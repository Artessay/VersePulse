model2path:
    qwen2.5-7b-instruct: qwen/qwen-2.5-7b-instruct
    llama3-8b-instruct: meta-llama/meta-llama-3.1-8B-instruct
model2pooling:
    e5: mean
    bge: cls
    contriever: mean
    jina: mean
    dpr: pooler
method2index:
    e5: null
    bm25: null
    contriever: null
    clip:
        text: null
        image: null
data_dir: dataset/
save_dir: output/mmlu_llama3-8b-instruct_experiment
gpu_id: 1,2,3,4
dataset_name: mmlu
split:
- test
test_sample_num: null
random_sample: false
seed: 2025
save_intermediate_data: true
save_note: experiment
retrieval_method: bm25
retrieval_model_path: bm25
index_name: wiki_en
index_path: null
multimodal_index_path_dict: null
faiss_gpu: false
corpus_path: null
instruction: null
retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: true
retrieval_query_max_length: 128
save_retrieval_cache: false
use_retrieval_cache: false
retrieval_cache_path: null
retrieval_pooling_method: mean
bm25_backend: bm25s
use_sentence_transformer: false
use_reranker: false
rerank_model_name: null
rerank_model_path: null
rerank_pooling_method: null
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 256
rerank_use_fp16: true
use_multi_retriever: false
multi_retriever_setting:
    merge_method: concat
    topk: 5
    rerank_model_name: null
    rerank_model_path: null
    retriever_list:
    -   retrieval_method: e5
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: e5
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
    -   retrieval_method: bm25
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: bm25
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
framework: fschat
generator_model: llama3-8b-instruct
openai_setting:
    api_key: null
    base_url: null
generator_model_path: /home/qrh/data/model/hub/models--meta-llama--meta-llama-3.1-8B-instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659
generator_max_input_len: 1024
generator_batch_size: 4
generation_params:
    max_tokens: 32
use_fid: false
gpu_memory_utilization: 0.85
metrics:
- em
- f1
- acc
- precision
- recall
- input_tokens
metric_setting:
    retrieval_recall_topk: 5
    tokenizer_name: gpt-4
save_metric_score: true
dataset_path: dataset/mmlu
gpu_num: 4
device: cuda
